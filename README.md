# üöÄ AstroETL: Automating NASA Data Pipelines with Airflow

A complete end-to-end ETL pipeline that extracts daily data from NASA's **Astronomy Picture of the Day (APOD)** API, transforms it, and loads it into a PostgreSQL database ‚Äî fully automated using **Apache Airflow (Astro Runtime)**.

---

## üìä Table of Contents

- [Project Overview](#project-overview)
- [Tech Stack](#tech-stack)
- [Architecture Diagram](#architecture-diagram)
- [Setup Instructions](#setup-instructions)
- [Airflow Configuration](#airflow-configuration)
- [Postgres Database Table](#postgres-database-table)
- [Pipeline Flow](#pipeline-flow)
- [Future Improvements](#future-improvements)
- [Demo Screenshot](#demo-screenshot)
- [License](#license)

---

## üåü Project Overview

This project demonstrates a real-world data engineering workflow:

- Connects with NASA‚Äôs public **Astronomy Picture of the Day (APOD)** API.
- Extracts image metadata and descriptions.
- Transforms raw API response into structured data.
- Loads data into PostgreSQL database.
- Fully orchestrated & scheduled using Apache Airflow (Astro Runtime).

---

## üõ† Tech Stack

| Tool           | Purpose                       |
| -------------- | ----------------------------- |
| Apache Airflow | Workflow orchestration        |
| Astro Runtime  | Simplified Airflow deployment |
| Python         | Core programming language     |
| PostgreSQL     | Data storage                  |
| NASA APOD API  | Public data source            |
| Docker         | Containerization              |
| DBeaver        | DB management & validation    |

---

## üõ† Architecture Diagram

```mermaid
flowchart LR
    NASA_API[NASA APOD API] --> Airflow_ETL[Airflow DAG]
    Airflow_ETL --> PostgresDB[PostgreSQL Database]
    PostgresDB --> DBeaver[Data Validation via DBeaver]
```

---

## üöÄ Setup Instructions

### 1‚É£ Clone the repository

```bash
git clone https://github.com/your-username/AstroETL-Automating-NASA-Data-Pipelines-with-Airflow.git
cd AstroETL-Automating-NASA-Data-Pipelines-with-Airflow
```

### 2‚É£ Initialize Astro Runtime (Airflow)

```bash
astro dev init
```

### 3‚É£ Install Astro CLI (if not installed)

```bash
brew install astro
# or follow https://docs.astronomer.io/astro/install-cli
```

### 4‚É£ Start Airflow locally

```bash
astro dev start
```

### 5‚É£ Access Airflow UI

Navigate to: [http://localhost:8080](http://localhost:8080)

Default credentials:

- Username: `admin`
- Password: `admin`

---

## ‚öô Airflow Configuration

#### 1‚É£ Add NASA API Connection

- **Connection ID:** `nasa_api`
- **Connection Type:** `HTTP`
- **Host:** `https://api.nasa.gov/`
- **Extras:**

```json
{"api_key": "YOUR_NASA_API_KEY"}
```

#### 2‚É£ Add Postgres Connection

- **Connection ID:** `my_postgres_connection`
- **Connection Type:** `Postgres`
- **Host:** `postgres`
- **Schema:** `postgres`
- **Login:** `postgres`
- **Password:** `postgres`
- **Port:** `5432`

---

## üìÑ PostgreSQL Database Table

The pipeline creates a table named `apod_data` with:

| Column      | Type               |
| ----------- | ------------------ |
| id          | SERIAL PRIMARY KEY |
| title       | VARCHAR(255)       |
| explanation | TEXT               |
| url         | TEXT               |
| date        | DATE               |
| media\_type | VARCHAR(50)        |

---

## üîÑ Pipeline Flow

1‚É£ **Extract:**\
Fetch data from NASA APOD API using `SimpleHttpOperator`.

2‚É£ **Transform:**\
Clean & filter required fields using `PythonTask`.

3‚É£ **Load:**\
Insert data into PostgreSQL using `PostgresHook`.

---

## üîß Future Improvements

- Add error handling and retries.
- Store images locally or on cloud storage.
- Build data quality checks.
- Add email or Slack alerts on DAG failures.
- Extend to multiple NASA APIs.

---

## üì∏ Demo Screenshot

*Airflow DAG Screenshot here (add once working)*

---

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ‚ú® Credits

Made with ‚ù§Ô∏è by Sadab Ali.

